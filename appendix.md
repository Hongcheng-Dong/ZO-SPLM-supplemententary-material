# ZO-SPLM Supplementary Material - Appendix

## Appendix A: Extended Mathematical Derivations

### A.1 Detailed Convergence Analysis

This section provides extended proofs and derivations for the convergence properties of the ZO-SPLM algorithm.

#### A.1.1 Smoothness and Lipschitz Conditions

**Definition A.1**: A function f: â„áµˆ â†’ â„ is L-smooth if:
||âˆ‡f(x) - âˆ‡f(y)|| â‰¤ L||x - y|| for all x, y âˆˆ â„áµˆ

**Lemma A.1**: Under L-smoothness, for any x, y âˆˆ â„áµˆ:
f(y) â‰¤ f(x) + âŸ¨âˆ‡f(x), y - xâŸ© + (L/2)||y - x||Â²

**Proof of Lemma A.1**:
Consider the function g(t) = f(x + t(y - x)) for t âˆˆ [0, 1].
By the fundamental theorem of calculus:
g(1) - g(0) = âˆ«â‚€Â¹ g'(t) dt = âˆ«â‚€Â¹ âŸ¨âˆ‡f(x + t(y - x)), y - xâŸ© dt

Adding and subtracting âŸ¨âˆ‡f(x), y - xâŸ©:
f(y) - f(x) = âŸ¨âˆ‡f(x), y - xâŸ© + âˆ«â‚€Â¹ âŸ¨âˆ‡f(x + t(y - x)) - âˆ‡f(x), y - xâŸ© dt

Using Cauchy-Schwarz and L-smoothness:
|âŸ¨âˆ‡f(x + t(y - x)) - âˆ‡f(x), y - xâŸ©| â‰¤ ||âˆ‡f(x + t(y - x)) - âˆ‡f(x)|| Â· ||y - x||
                                        â‰¤ Lt||y - x||Â²

Therefore:
f(y) - f(x) â‰¤ âŸ¨âˆ‡f(x), y - xâŸ© + âˆ«â‚€Â¹ Lt||y - x||Â² dt = âŸ¨âˆ‡f(x), y - xâŸ© + (L/2)||y - x||Â² â–¡

#### A.1.2 Zeroth-Order Gradient Estimation

**Definition A.2**: The coordinate-wise finite difference estimator is:
Äáµ¢(x) = [f(x + Î¼eáµ¢) - f(x - Î¼eáµ¢)]/(2Î¼)

where eáµ¢ is the i-th coordinate vector and Î¼ > 0 is the smoothing parameter.

**Lemma A.2**: For twice-differentiable f with bounded Hessian ||âˆ‡Â²f(x)|| â‰¤ M:
|ğ”¼[Äáµ¢(x)] - âˆ‚f/âˆ‚xáµ¢(x)| â‰¤ (MÎ¼Â²/6)

**Proof of Lemma A.2**:
By Taylor expansion around x:
f(x Â± Î¼eáµ¢) = f(x) Â± Î¼âˆ‚f/âˆ‚xáµ¢(x) + (Î¼Â²/2)âˆ‚Â²f/âˆ‚xáµ¢Â²(Î¾áµ¢Â±) + O(Î¼Â³)

where Î¾áµ¢Â± lie between x and x Â± Î¼eáµ¢.

Therefore:
Äáµ¢(x) = âˆ‚f/âˆ‚xáµ¢(x) + (Î¼/4)[âˆ‚Â²f/âˆ‚xáµ¢Â²(Î¾áµ¢âº) + âˆ‚Â²f/âˆ‚xáµ¢Â²(Î¾áµ¢â»)] + O(Î¼Â²)

The bias is:
|ğ”¼[Äáµ¢(x)] - âˆ‚f/âˆ‚xáµ¢(x)| = (Î¼/4)|ğ”¼[âˆ‚Â²f/âˆ‚xáµ¢Â²(Î¾áµ¢âº) + âˆ‚Â²f/âˆ‚xáµ¢Â²(Î¾áµ¢â»)]| + O(Î¼Â²)

Since ||âˆ‡Â²f|| â‰¤ M, we have |âˆ‚Â²f/âˆ‚xáµ¢Â²| â‰¤ M, giving the bound (MÎ¼Â²/6). â–¡

### A.2 Variance Analysis

**Lemma A.3**: Under additive noise model f_obs(x) = f(x) + Î¾ where ğ”¼[Î¾] = 0, Var[Î¾] = ÏƒÂ²:
Var[Äáµ¢(x)] = ÏƒÂ²/Î¼Â²

**Proof of Lemma A.3**:
Äáµ¢(x) = [f_obs(x + Î¼eáµ¢) - f_obs(x - Î¼eáµ¢)]/(2Î¼)
       = [f(x + Î¼eáµ¢) - f(x - Î¼eáµ¢)]/(2Î¼) + [Î¾âº - Î¾â»]/(2Î¼)

where Î¾Â± are independent noise terms with variance ÏƒÂ².

Since f is deterministic:
Var[Äáµ¢(x)] = Var[(Î¾âº - Î¾â»)/(2Î¼)] = [Var[Î¾âº] + Var[Î¾â»]]/(4Î¼Â²) = 2ÏƒÂ²/(4Î¼Â²) = ÏƒÂ²/(2Î¼Â²) â–¡

### A.3 Optimal Smoothing Parameter

**Theorem A.1**: The optimal smoothing parameter minimizing MSE is:
Î¼* = (3Ïƒ/M)^(1/3)

**Proof of Theorem A.1**:
MSE = BiasÂ² + Variance â‰¤ (MÎ¼Â²/6)Â² + ÏƒÂ²/Î¼Â²

Taking derivative with respect to Î¼:
d/dÎ¼ MSE = 2(MÎ¼Â²/6)(M/3) - 2ÏƒÂ²/Î¼Â³ = MÂ²Î¼/18 - 2ÏƒÂ²/Î¼Â³

Setting equal to zero:
MÂ²Î¼/18 = 2ÏƒÂ²/Î¼Â³
Î¼â´ = 36ÏƒÂ²/MÂ²
Î¼ = (36ÏƒÂ²/MÂ²)^(1/4) = (3Ïƒ/M)^(1/3) Â· 6^(1/4)

The leading term gives Î¼* = (3Ïƒ/M)^(1/3). â–¡

## Appendix B: Algorithm Implementation Details

### B.1 ZO-SPLM Algorithm Pseudocode

```
Algorithm: ZO-SPLM (Zeroth-Order Structured Probabilistic Learning Method)

Input: 
  - f: objective function
  - xâ‚€: initial point
  - Î¼: smoothing parameter
  - Î±: step size schedule
  - T: maximum iterations

Output: x_T (approximate stationary point)

1: Initialize x â† xâ‚€
2: for t = 0 to T-1 do
3:   for i = 1 to d do
4:     Äáµ¢ â† [f(x + Î¼eáµ¢) - f(x - Î¼eáµ¢)]/(2Î¼)
5:   end for
6:   Ä â† (Äâ‚, ..., Ä_d)
7:   x â† x - Î±_t Ä
8: end for
9: return x
```

### B.2 Adaptive Parameter Selection

**Algorithm B.1**: Adaptive Smoothing Parameter
```
1: Initialize Î¼â‚€, adaptation rate Î²
2: for t = 0 to T-1 do
3:   Estimate local curvature: Ä¤â‚œ â† estimate_curvature(xâ‚œ)
4:   Estimate noise level: ÏƒÌ‚â‚œ â† estimate_noise(xâ‚œ)
5:   Update smoothing: Î¼â‚œâ‚Šâ‚ â† (1-Î²)Î¼â‚œ + Î²(ÏƒÌ‚â‚œ/||Ä¤â‚œ||)^(1/3)
6: end for
```

### B.3 Complexity Analysis

**Space Complexity**: O(d) for storing current iterate and gradient estimate.

**Time Complexity**: O(d) per iteration for gradient estimation, O(TÂ·d) total.

**Function Evaluation Complexity**: 2d evaluations per iteration, 2Td total.

## Appendix C: Experimental Validation Framework

### C.1 Test Functions

We validate our theoretical results on the following test functions:

**C.1.1 Quadratic Function**
fâ‚(x) = (1/2)x^T A x + b^T x + c
where A is positive definite.

**C.1.2 Rosenbrock Function**
fâ‚‚(x) = âˆ‘áµ¢â‚Œâ‚^(d-1) [100(xáµ¢â‚Šâ‚ - xáµ¢Â²)Â² + (1 - xáµ¢)Â²]

**C.1.3 Rastrigin Function**
fâ‚ƒ(x) = 10d + âˆ‘áµ¢â‚Œâ‚^d [xáµ¢Â² - 10cos(2Ï€xáµ¢)]

### C.2 Performance Metrics

1. **Convergence Rate**: ||âˆ‡f(xâ‚œ)||Â² vs iteration count
2. **Function Value Decrease**: f(xâ‚œ) - f* vs iteration count  
3. **Sample Complexity**: Number of function evaluations to reach Îµ-accuracy
4. **Robustness**: Performance under different noise levels

### C.3 Experimental Protocol

1. **Initialization**: Random starting points from unit ball
2. **Noise Model**: Additive Gaussian noise N(0, ÏƒÂ²)
3. **Parameter Tuning**: Grid search over Î¼ and Î±
4. **Repetitions**: 50 independent runs per configuration
5. **Statistical Analysis**: Mean, confidence intervals, significance tests

## Appendix D: Comparison with Related Methods

### D.1 Classical Finite Difference Methods

**Standard Finite Difference**:
Äáµ¢^FD(x) = [f(x + Î¼eáµ¢) - f(x)]/Î¼

**Bias**: O(Î¼), **Variance**: O(ÏƒÂ²/Î¼Â²)
**Optimal Î¼**: O((ÏƒÂ²/L)^(1/3))

### D.2 Random Direction Methods

**Gaussian Smoothing**:
Ä^GS(x) = (d/Î¼Â²)[f(x + Î¼u) - f(x)]u

where u ~ N(0, I).

**Bias**: O(Î¼Â²), **Variance**: O(dÏƒÂ²/Î¼Â²)
**Optimal Î¼**: O((ÏƒÂ²/L)^(1/3))

### D.3 Sphere Smoothing

**Two-Point Estimate**:
Ä^SP(x) = (d/Î¼)[f(x + Î¼u) - f(x - Î¼u)]u/(2)

where u is uniform on unit sphere.

**Bias**: O(Î¼Â²), **Variance**: O(dÏƒÂ²/Î¼Â²)

### D.4 Performance Comparison

| Method | Function Evaluations | Bias | Variance | Optimal Rate |
|--------|-------------------|------|----------|--------------|
| ZO-SPLM | 2d | O(Î¼Â²) | O(dÏƒÂ²/Î¼Â²) | O(d/ÎµÂ²) |
| Standard FD | d+1 | O(Î¼) | O(dÏƒÂ²/Î¼Â²) | O(d/ÎµÂ³) |
| Gaussian Smooth | 2 | O(Î¼Â²) | O(dÏƒÂ²/Î¼Â²) | O(dÂ²/ÎµÂ²) |
| Sphere Smooth | 2 | O(Î¼Â²) | O(dÏƒÂ²/Î¼Â²) | O(dÂ²/ÎµÂ²) |

## Appendix E: Extensions and Future Work

### E.1 Stochastic Extensions

Extension to stochastic settings where f(x) = ğ”¼[F(x, Î¾)] with Î¾ random.

**Modified Algorithm**:
1. Sample batch of size B: {Î¾â‚, ..., Î¾_B}
2. Estimate: fÌ‚(x) = (1/B)âˆ‘â±¼â‚Œâ‚^B F(x, Î¾â±¼)
3. Apply ZO-SPLM to fÌ‚

**Additional Complexity**: Factor of B in function evaluations.

### E.2 Constrained Optimization

Extension to constrained problems: min f(x) s.t. x âˆˆ C

**Projected ZO-SPLM**:
x_{t+1} = Î _C(x_t - Î±_t Ä_t)

where Î _C is projection onto constraint set C.

### E.3 Non-smooth Extensions

For non-smooth f, use smoothing techniques:
f_Î¼(x) = ğ”¼[f(x + Î¼U)]

where U is appropriate smoothing distribution.

---

*This appendix provides comprehensive technical details supporting the main theoretical and algorithmic contributions of ZO-SPLM. For practical implementation guidance, refer to the accompanying code repository.*